{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sequence2Sequence(Encoder-Decoder)_with_Attention(Text Generation)_v02.ipynb","provenance":[{"file_id":"1KLoVFvyQiuSdsHOZBk9aaJa2lngfEc30","timestamp":1571486051241},{"file_id":"1WdCWabSymMfhOJK1ejzzUVgkIpflCxtn","timestamp":1571323202479}],"collapsed_sections":["gS_ZDDvjIkos"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"53xgu7v-XMEo","colab_type":"code","outputId":"c18fe377-c59c-4330-c64a-00cd3d2b739a","executionInfo":{"status":"ok","timestamp":1571532890581,"user_tz":-330,"elapsed":20023,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rB2QmaGgIJG6","colab_type":"code","outputId":"00f16a48-356d-47dc-fe8e-8e869e15b1f7","executionInfo":{"status":"ok","timestamp":1571532900692,"user_tz":-330,"elapsed":8450,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["!git clone https://github.com/totalgood/nlpia.git"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Cloning into 'nlpia'...\n","remote: Enumerating objects: 196, done.\u001b[K\n","remote: Counting objects:   0% (1/196)\u001b[K\rremote: Counting objects:   1% (2/196)\u001b[K\rremote: Counting objects:   2% (4/196)\u001b[K\rremote: Counting objects:   3% (6/196)\u001b[K\rremote: Counting objects:   4% (8/196)\u001b[K\rremote: Counting objects:   5% (10/196)\u001b[K\rremote: Counting objects:   6% (12/196)\u001b[K\rremote: Counting objects:   7% (14/196)\u001b[K\rremote: Counting objects:   8% (16/196)\u001b[K\rremote: Counting objects:   9% (18/196)\u001b[K\rremote: Counting objects:  10% (20/196)\u001b[K\rremote: Counting objects:  11% (22/196)\u001b[K\rremote: Counting objects:  12% (24/196)\u001b[K\rremote: Counting objects:  13% (26/196)\u001b[K\rremote: Counting objects:  14% (28/196)\u001b[K\rremote: Counting objects:  15% (30/196)\u001b[K\rremote: Counting objects:  16% (32/196)\u001b[K\rremote: Counting objects:  17% (34/196)\u001b[K\rremote: Counting objects:  18% (36/196)\u001b[K\rremote: Counting objects:  19% (38/196)\u001b[K\rremote: Counting objects:  20% (40/196)\u001b[K\rremote: Counting objects:  21% (42/196)\u001b[K\rremote: Counting objects:  22% (44/196)\u001b[K\rremote: Counting objects:  23% (46/196)\u001b[K\rremote: Counting objects:  24% (48/196)\u001b[K\rremote: Counting objects:  25% (49/196)\u001b[K\rremote: Counting objects:  26% (51/196)\u001b[K\rremote: Counting objects:  27% (53/196)\u001b[K\rremote: Counting objects:  28% (55/196)\u001b[K\rremote: Counting objects:  29% (57/196)\u001b[K\rremote: Counting objects:  30% (59/196)\u001b[K\rremote: Counting objects:  31% (61/196)\u001b[K\rremote: Counting objects:  32% (63/196)\u001b[K\rremote: Counting objects:  33% (65/196)\u001b[K\rremote: Counting objects:  34% (67/196)\u001b[K\rremote: Counting objects:  35% (69/196)\u001b[K\rremote: Counting objects:  36% (71/196)\u001b[K\rremote: Counting objects:  37% (73/196)\u001b[K\rremote: Counting objects:  38% (75/196)\u001b[K\rremote: Counting objects:  39% (77/196)\u001b[K\rremote: Counting objects:  40% (79/196)\u001b[K\rremote: Counting objects:  41% (81/196)\u001b[K\rremote: Counting objects:  42% (83/196)\u001b[K\rremote: Counting objects:  43% (85/196)\u001b[K\rremote: Counting objects:  44% (87/196)\u001b[K\rremote: Counting objects:  45% (89/196)\u001b[K\rremote: Counting objects:  46% (91/196)\u001b[K\rremote: Counting objects:  47% (93/196)\u001b[K\rremote: Counting objects:  48% (95/196)\u001b[K\rremote: Counting objects:  49% (97/196)\u001b[K\rremote: Counting objects:  50% (98/196)\u001b[K\rremote: Counting objects:  51% (100/196)\rremote: Counting objects:  52% (102/196)\u001b[K\rremote: Counting objects:  53% (104/196)\u001b[K\rremote: Counting objects:  54% (106/196)\u001b[K\rremote: Counting objects:  55% (108/196)\u001b[K\rremote: Counting objects:  56% (110/196)\u001b[K\rremote: Counting objects:  57% (112/196)\u001b[K\rremote: Counting objects:  58% (114/196)\u001b[K\rremote: Counting objects:  59% (116/196)\u001b[K\rremote: Counting objects:  60% (118/196)\u001b[K\rremote: Counting objects:  61% (120/196)\u001b[K\rremote: Counting objects:  62% (122/196)\u001b[K\rremote: Counting objects:  63% (124/196)\u001b[K\rremote: Counting objects:  64% (126/196)\u001b[K\rremote: Counting objects:  65% (128/196)\u001b[K\rremote: Counting objects:  66% (130/196)\u001b[K\rremote: Counting objects:  67% (132/196)\u001b[K\rremote: Counting objects:  68% (134/196)\u001b[K\rremote: Counting objects:  69% (136/196)\u001b[K\rremote: Counting objects:  70% (138/196)\u001b[K\rremote: Counting objects:  71% (140/196)\u001b[K\rremote: Counting objects:  72% (142/196)\u001b[K\rremote: Counting objects:  73% (144/196)\u001b[K\rremote: Counting objects:  74% (146/196)\u001b[K\rremote: Counting objects:  75% (147/196)\u001b[K\rremote: Counting objects:  76% (149/196)\u001b[K\rremote: Counting objects:  77% (151/196)\u001b[K\rremote: Counting objects:  78% (153/196)\u001b[K\rremote: Counting objects:  79% (155/196)\u001b[K\rremote: Counting objects:  80% (157/196)\u001b[K\rremote: Counting objects:  81% (159/196)\u001b[K\rremote: Counting objects:  82% (161/196)\u001b[K\rremote: Counting objects:  83% (163/196)\u001b[K\rremote: Counting objects:  84% (165/196)\u001b[K\rremote: Counting objects:  85% (167/196)\u001b[K\rremote: Counting objects:  86% (169/196)\u001b[K\rremote: Counting objects:  87% (171/196)\u001b[K\rremote: Counting objects:  88% (173/196)\u001b[K\rremote: Counting objects:  89% (175/196)\u001b[K\rremote: Counting objects:  90% (177/196)\u001b[K\rremote: Counting objects:  91% (179/196)\u001b[K\rremote: Counting objects:  92% (181/196)\u001b[K\rremote: Counting objects:  93% (183/196)\u001b[K\rremote: Counting objects:  94% (185/196)\u001b[K\rremote: Counting objects:  95% (187/196)\u001b[K\rremote: Counting objects:  96% (189/196)\u001b[K\rremote: Counting objects:  97% (191/196)\u001b[K\rremote: Counting objects:  98% (193/196)\u001b[K\rremote: Counting objects:  99% (195/196)\u001b[K\rremote: Counting objects: 100% (196/196)\u001b[K\rremote: Counting objects: 100% (196/196), done.\u001b[K\n","remote: Compressing objects: 100% (118/118), done.\u001b[K\n","remote: Total 5827 (delta 98), reused 138 (delta 57), pack-reused 5631\u001b[K\n","Receiving objects: 100% (5827/5827), 124.02 MiB | 28.12 MiB/s, done.\n","Resolving deltas: 100% (3674/3674), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3FXYYs2FIpJU","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mDJryqyGIfIi","colab_type":"code","colab":{}},"source":["df = pd.read_csv('/content/nlpia/src/nlpia/data/moviedialog.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZCWX8-97IfMZ","colab_type":"code","colab":{}},"source":["df.drop(columns='Unnamed: 0', axis=1,inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QPzSUj5PIfPv","colab_type":"code","outputId":"fcac9bdc-a7d7-4be4-ec06-cb67cd6cfe07","executionInfo":{"status":"ok","timestamp":1571535447976,"user_tz":-330,"elapsed":1039,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["df.head(5)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>statement</th>\n","      <th>reply</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>you're asking me out. that's so cute. what's y...</td>\n","      <td>forget it.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>no, no, it's my fault we didn't have a proper ...</td>\n","      <td>cameron.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>gosh, if only we could find kat a boyfriend...</td>\n","      <td>let me see what i can do.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>c'esc ma tete. this is my head</td>\n","      <td>right. see? you're ready for the quiz.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>how is our little find the wench a date plan p...</td>\n","      <td>well, there's someone i think might be</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                           statement                                    reply\n","0  you're asking me out. that's so cute. what's y...                               forget it.\n","1  no, no, it's my fault we didn't have a proper ...                                 cameron.\n","2     gosh, if only we could find kat a boyfriend...                let me see what i can do.\n","3                     c'esc ma tete. this is my head   right. see? you're ready for the quiz.\n","4  how is our little find the wench a date plan p...  well, there's someone i think might be "]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"8Dmch6easgkA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"a7ba7242-adbe-494e-8d91-3f527d415cc8","executionInfo":{"status":"ok","timestamp":1571535449150,"user_tz":-330,"elapsed":2010,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}}},"source":["df.shape"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(64350, 2)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"kiYcCvtjP8Mk","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import os\n","from tensorflow.python.keras.layers import Layer\n","from tensorflow.python.keras import backend as K\n","\n","\n","class AttentionLayer(Layer):\n","    \"\"\"\n","    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n","    There are three sets of weights introduced W_a, U_a, and V_a\n","     \"\"\"\n","\n","    def __init__(self, **kwargs):\n","        super(AttentionLayer, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        assert isinstance(input_shape, list)\n","        # Create a trainable weight variable for this layer.\n","\n","        self.W_a = self.add_weight(name='W_a',\n","                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n","                                   initializer='uniform',\n","                                   trainable=True)\n","        self.U_a = self.add_weight(name='U_a',\n","                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n","                                   initializer='uniform',\n","                                   trainable=True)\n","        self.V_a = self.add_weight(name='V_a',\n","                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n","                                   initializer='uniform',\n","                                   trainable=True)\n","\n","        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n","\n","    def call(self, inputs, verbose=False):\n","        \"\"\"\n","        inputs: [encoder_output_sequence, decoder_output_sequence]\n","        \"\"\"\n","        assert type(inputs) == list\n","        encoder_out_seq, decoder_out_seq = inputs\n","        if verbose:\n","            print('encoder_out_seq>', encoder_out_seq.shape)\n","            print('decoder_out_seq>', decoder_out_seq.shape)\n","\n","        def energy_step(inputs, states):\n","            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n","\n","            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n","            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n","\n","            \"\"\" Some parameters required for shaping tensors\"\"\"\n","            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n","            de_hidden = inputs.shape[-1]\n","\n","            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n","            # <= batch_size*en_seq_len, latent_dim\n","            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n","            # <= batch_size*en_seq_len, latent_dim\n","            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n","            if verbose:\n","                print('wa.s>',W_a_dot_s.shape)\n","\n","            \"\"\" Computing hj.Ua \"\"\"\n","            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n","            if verbose:\n","                print('Ua.h>',U_a_dot_h.shape)\n","\n","            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n","            # <= batch_size*en_seq_len, latent_dim\n","            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n","            if verbose:\n","                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n","\n","            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n","            # <= batch_size, en_seq_len\n","            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n","            # <= batch_size, en_seq_len\n","            e_i = K.softmax(e_i)\n","\n","            if verbose:\n","                print('ei>', e_i.shape)\n","\n","            return e_i, [e_i]\n","\n","        def context_step(inputs, states):\n","            \"\"\" Step function for computing ci using ei \"\"\"\n","            # <= batch_size, hidden_size\n","            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n","            if verbose:\n","                print('ci>', c_i.shape)\n","            return c_i, [c_i]\n","\n","        def create_inital_state(inputs, hidden_size):\n","            # We are not using initial states, but need to pass something to K.rnn funciton\n","            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n","            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n","            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n","            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n","            return fake_state\n","\n","        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n","        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n","\n","        \"\"\" Computing energy outputs \"\"\"\n","        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n","        last_out, e_outputs, _ = K.rnn(\n","            energy_step, decoder_out_seq, [fake_state_e],\n","        )\n","\n","        \"\"\" Computing context vectors \"\"\"\n","        last_out, c_outputs, _ = K.rnn(\n","            context_step, e_outputs, [fake_state_c],\n","        )\n","\n","        return c_outputs, e_outputs\n","\n","    def compute_output_shape(self, input_shape):\n","        \"\"\" Outputs produced by the layer \"\"\"\n","        return [\n","            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n","            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n","        ]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aPabITAaLVDd","colab_type":"text"},"source":["# Preprocessing"]},{"cell_type":"code","metadata":{"id":"s8Y1yohx6231","colab_type":"code","colab":{}},"source":["contraction_mapping = {\"ain't\": \"is not\",\n","                       \"aren't\": \"are not\",\n","                       \"can't\": \"cannot\",\n","                       \"'cause\": \"because\",\n","                       \"could've\": \"could have\",\n","                       \"couldn't\": \"could not\",\n","                      \"didn't\": \"did not\",\n","                       \"doesn't\": \"does not\",\n","                       \"don't\": \"do not\",\n","                      \"hadn't\": \"had not\",\n","                       \"hasn't\": \"has not\",\n","                       \"haven't\": \"have not\",\n","                        \"he'd\": \"he would\",\n","                       \"he'll\": \"he will\",\n","                       \"he's\": \"he is\",\n","                        \"how'd\": \"how did\",\n","                        \"how'd'y\": \"how do you\",\n","                        \"how'll\": \"how will\",\n","                        \"how's\": \"how is\",\n","                        \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n","\n","                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n","\n","                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n","\n","                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n","\n","                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n","\n","                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n","\n","                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n","\n","                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n","\n","                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n","\n","                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n","\n","                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n","\n","                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n","\n","                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n","\n","                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n","\n","                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n","\n","                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n","\n","                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n","\n","                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n","\n","                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n","\n","                           \"you're\": \"you are\", \"you've\": \"you have\"}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5wlXD8aX4Kc1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"a8577a88-3743-440f-a251-abe04e469006","executionInfo":{"status":"ok","timestamp":1571535478022,"user_tz":-330,"elapsed":1110,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}}},"source":["data_input = [s.lower() for s in df['statement']]\n","data_output = [s.lower() for s in df['reply']]\n","\n","print(data_input[0:3])\n","print(data_output[0:3])"],"execution_count":19,"outputs":[{"output_type":"stream","text":["[\"you're asking me out. that's so cute. what's your name again?\", \"no, no, it's my fault we didn't have a proper introduction \", 'gosh, if only we could find kat a boyfriend...']\n","['forget it.', 'cameron.', 'let me see what i can do.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ceEelPFc4KkI","colab_type":"code","colab":{}},"source":["cleaned_text = []\n","for w in data_input:\n","  newstring = ' '.join([contraction_mapping[c] if c in contraction_mapping else c for c in w.split(\" \")])\n","  cleaned_text.append(newstring)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O5ByEQt24Kp-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"0bee4c38-f5d3-4995-b70d-c442d1057e37","executionInfo":{"status":"ok","timestamp":1571535479559,"user_tz":-330,"elapsed":584,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}}},"source":["cleaned_text[0:3]"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['you are asking me out. that is so cute. what is your name again?',\n"," 'no, no, it is my fault we did not have a proper introduction ',\n"," 'gosh, if only we could find kat a boyfriend...']"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"KUI-aZnh4Ku9","colab_type":"code","colab":{}},"source":["cleaned_summary = []\n","for w in data_output:\n","  newstring = ' '.join([contraction_mapping[c] if c in contraction_mapping else c for c in w.split(\" \")])\n","  tokens=newstring.split()\n","  newstring=''\n","  for char in tokens:\n","    if len(char) > 1:\n","      newstring = newstring+char+' '\n","  cleaned_summary.append(newstring)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uHrDrowFqsEs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"af287bd1-d4b8-4360-e74e-66b72eb209bf","executionInfo":{"status":"ok","timestamp":1571535484798,"user_tz":-330,"elapsed":807,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}}},"source":["cleaned_summary[0:3]"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['forget it. ', 'cameron. ', 'let me see what can do. ']"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"xVm2aEcV4K0f","colab_type":"code","colab":{}},"source":["df['cleaned_text']=cleaned_text\n","df['cleaned_summary']=cleaned_summary\n","df['cleaned_summary'].replace('', np.nan, inplace=True)\n","df.dropna(axis=0,inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"soAhX_QNs1tH","colab_type":"code","colab":{}},"source":["df.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ANBoYxRF4K50","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"c74ea7ca-94db-42ee-bf27-0cda60040b06","executionInfo":{"status":"ok","timestamp":1571535541627,"user_tz":-330,"elapsed":927,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}}},"source":["data_inputs = [s.lower() for s in df['cleaned_text']]\n","data_outputs = [s.lower() for s in df['cleaned_summary']]\n","\n","data_size = len(df)\n","\n","split_index = int(data_size*80/100)\n","# print(split_index)\n","# validation_split_index = int(data_size*70/100)\n","\n","# We will use the first 0-60th %-tile (60%) of data for the training\n","training_input  = data_inputs[:split_index]\n","training_output = data_outputs[:split_index]\n","\n","# # We will use the first 60-70th %-tile (10%) of data for the training\n","validation_input = data_inputs[split_index:]\n","validation_output = data_outputs[split_index:]\n","\n","print(len(training_input))\n","print(len(validation_input))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["51428\n","12857\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-8KT69AetAyk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"4a760ab6-0e11-4354-8263-0669bc9f2348","executionInfo":{"status":"ok","timestamp":1571535548615,"user_tz":-330,"elapsed":819,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}}},"source":["training_input[0:3]"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['you are asking me out. that is so cute. what is your name again?',\n"," 'no, no, it is my fault we did not have a proper introduction ',\n"," 'gosh, if only we could find kat a boyfriend...']"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"eMHS_w6ytDoV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"641bb5b2-9929-452d-e991-0ad4d89215a5","executionInfo":{"status":"ok","timestamp":1571535551528,"user_tz":-330,"elapsed":1077,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}}},"source":["training_output[0:3]"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['forget it. ', 'cameron. ', 'let me see what can do. ']"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"p0aLVqYN4K_D","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"15d071f0-3fe7-40d4-b3cf-99da3ede7e98","executionInfo":{"status":"ok","timestamp":1571537708152,"user_tz":-330,"elapsed":808,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}}},"source":["START_CHAR_CODE = 1\n","\n","def encode_characters(titles):\n","    count = 2\n","    encoding = {}\n","    decoding = {1: 'START'}\n","    for c in set([c for title in titles for c in title]):\n","        encoding[c] = count\n","        decoding[count] = c\n","        count += 1\n","    return encoding, decoding, count\n","\n","\n","statement_encoding, statement_decoding, statement_dict_size = encode_characters(data_inputs)\n","reply_encoding, reply_decoding, reply_dict_size = encode_characters(data_outputs)\n","\n","print('statement character dict size:', statement_dict_size)\n","print('reply character dict size:', reply_dict_size)\n","\n","print(list(statement_encoding.items())[0:5])\n","print(list(reply_encoding.items())[0:5])\n","\n"],"execution_count":59,"outputs":[{"output_type":"stream","text":["statement character dict size: 46\n","reply character dict size: 46\n","[('p', 2), (';', 3), ('3', 4), ('1', 5), ('o', 6)]\n","[('p', 2), (';', 3), ('3', 4), ('1', 5), ('o', 6)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LBt0yVvL2hO_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":255},"outputId":"365d1671-9cd5-484e-bff8-0b0ab8059dfd","executionInfo":{"status":"ok","timestamp":1571538485771,"user_tz":-330,"elapsed":2550,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}}},"source":["def transform(encoding, data, vector_size):\n","    transformed_data = np.zeros(shape=(len(data), vector_size), dtype='int')\n","    for i in range(len(data)):\n","        for j in range(min(len(data[i]), vector_size)):\n","            transformed_data[i][j] = encoding[data[i][j]]\n","    return transformed_data\n","\n","INPUT_LENGTH = 80\n","OUTPUT_LENGTH = 80\n","\n","encoded_training_input = transform(statement_encoding, training_input, vector_size=INPUT_LENGTH)\n","encoded_training_output = transform(reply_encoding, training_output, vector_size=OUTPUT_LENGTH)\n","encoded_validation_input = transform(statement_encoding, validation_input, vector_size=INPUT_LENGTH)\n","encoded_validation_output = transform(reply_encoding, validation_output, vector_size=OUTPUT_LENGTH)\n","\n","print('input', encoded_training_input)\n","print('output', encoded_training_output)"],"execution_count":61,"outputs":[{"output_type":"stream","text":["input [[10  6 44 ...  0  0  0]\n"," [31  6 13 ...  0  0  0]\n"," [34  6 20 ...  0  0  0]\n"," ...\n"," [29 35 10 ...  0  0  0]\n"," [32 44 41 ...  0  0  0]\n"," [10  6 44 ...  0  0  0]]\n","output [[11  6 17 ...  0  0  0]\n"," [37 34 12 ...  0  0  0]\n"," [32 28  7 ...  0  0  0]\n"," ...\n"," [35 34 15 ...  0  0  0]\n"," [35 18 13 ...  0  0  0]\n"," [10 28 34 ...  0  0  0]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qa0OY8yh_0yz","colab_type":"code","colab":{}},"source":["from __future__ import print_function\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","\n","from tensorflow.keras.layers import Input, Embedding, LSTM, TimeDistributed, Dense\n","from tensorflow.keras.models import Model, load_model\n","\n","from tensorflow.keras.layers import Activation, dot, concatenate"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yx9fU46-2hcA","colab_type":"code","colab":{}},"source":["encoder_input = Input(shape=(INPUT_LENGTH,))\n","decoder_input = Input(shape=(OUTPUT_LENGTH,))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nuGbHUsr2hjC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":207},"outputId":"18c03b03-83ac-4038-9e5a-ec225a0c7c87","executionInfo":{"status":"ok","timestamp":1571539237983,"user_tz":-330,"elapsed":1148,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}}},"source":["# Encoder\n","# encoder = Embedding(statement_dict_size, 64, input_length=INPUT_LENGTH, mask_zero=True)(encoder_input)\n","# encoder = LSTM(64)(encoder)\n","\n","# print(encoder.get_shape())"],"execution_count":66,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py:3994: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","(?, 64)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N8i3t_rG2hpU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"509c2cf3-0592-4733-bcac-9b7ba9c7d94a","executionInfo":{"status":"ok","timestamp":1571539279471,"user_tz":-330,"elapsed":973,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}}},"source":["# decoder = Embedding(reply_dict_size, 64, input_length=OUTPUT_LENGTH, mask_zero=True)(decoder_input)\n","\n","# decoder = LSTM(64, return_sequences=True)(decoder, initial_state=[encoder, encoder])\n","# decoder = TimeDistributed(Dense(reply_dict_size, activation=\"softmax\"))(decoder)\n","\n","# print(decoder.get_shape())"],"execution_count":68,"outputs":[{"output_type":"stream","text":["(?, 80, 46)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gLgQ7CGt2hv5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"5c28e4a9-617d-441e-d378-39d73c2721c3","executionInfo":{"status":"ok","timestamp":1571539384666,"user_tz":-330,"elapsed":9390,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}}},"source":["encoder = Embedding(statement_dict_size, 64, input_length=INPUT_LENGTH, mask_zero=True)(encoder_input)\n","encoder_output, state_h, state_c = LSTM(64, return_sequences=True, return_state=True, unroll=True)(encoder)\n","# encoder = LSTM(64, return_sequences=True, unroll=True)(encoder)\n","# encoder_last = encoder[:,-1,:]\n","\n","# print('encoder', encoder)\n","# print('encoder_last', encoder_last)\n","\n","decoder = Embedding(reply_dict_size, 64, input_length=OUTPUT_LENGTH, mask_zero=True)(decoder_input)\n","decoder_output,decoder_fwd_state,decoder_back_state = LSTM(64, return_sequences=True, return_state=True, unroll=True)(decoder, initial_state=[state_h, state_c])\n","# decoder = LSTM(64, return_sequences=True, unroll=True)(decoder, initial_state=[encoder_last, encoder_last])\n","\n","print('decoder', decoder)"],"execution_count":69,"outputs":[{"output_type":"stream","text":["decoder Tensor(\"embedding_4/embedding_lookup/Identity_1:0\", shape=(?, 80, 64), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a6OkVGXK2h2c","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"79ea6650-ded1-47d0-f73e-f40822707379","executionInfo":{"status":"ok","timestamp":1571539424680,"user_tz":-330,"elapsed":893,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}}},"source":["# Equation (7) with 'dot' score from Section 3.1 in the paper.\n","# Note that we reuse Softmax-activation layer instead of writing tensor calculation\n","attention = dot([decoder, encoder], axes=[2, 2])\n","attention = Activation('softmax', name='attention')(attention)\n","print('attention', attention)\n","\n","context = dot([attention, encoder], axes=[2,1])\n","print('context', context)\n","\n","decoder_combined_context = concatenate([context, decoder])\n","print('decoder_combined_context', decoder_combined_context)\n","\n","# Has another weight + tanh layer as described in equation (5) of the paper\n","output = TimeDistributed(Dense(64, activation=\"tanh\"))(decoder_combined_context)\n","output = TimeDistributed(Dense(reply_dict_size, activation=\"softmax\"))(output)\n","print('output', output)"],"execution_count":70,"outputs":[{"output_type":"stream","text":["attention Tensor(\"attention/truediv:0\", shape=(?, 80, 80), dtype=float32)\n","context Tensor(\"dot_1/MatMul:0\", shape=(?, 80, 64), dtype=float32)\n","decoder_combined_context Tensor(\"concatenate/concat:0\", shape=(?, 80, 128), dtype=float32)\n","output Tensor(\"time_distributed_2/Reshape_1:0\", shape=(?, 80, 46), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M64BROMB2h9Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":544},"outputId":"fbb7409d-65a7-490d-f4ee-9dafc4fd22bc","executionInfo":{"status":"ok","timestamp":1571539437021,"user_tz":-330,"elapsed":795,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}}},"source":["model = Model(inputs=[encoder_input, decoder_input], outputs=[output])\n","model.compile(optimizer='adam', loss='categorical_crossentropy')\n","model.summary()"],"execution_count":71,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            [(None, 80)]         0                                            \n","__________________________________________________________________________________________________\n","input_1 (InputLayer)            [(None, 80)]         0                                            \n","__________________________________________________________________________________________________\n","embedding_4 (Embedding)         (None, 80, 64)       2944        input_2[0][0]                    \n","__________________________________________________________________________________________________\n","embedding_3 (Embedding)         (None, 80, 64)       2944        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","dot (Dot)                       (None, 80, 80)       0           embedding_4[0][0]                \n","                                                                 embedding_3[0][0]                \n","__________________________________________________________________________________________________\n","attention (Activation)          (None, 80, 80)       0           dot[0][0]                        \n","__________________________________________________________________________________________________\n","dot_1 (Dot)                     (None, 80, 64)       0           attention[0][0]                  \n","                                                                 embedding_3[0][0]                \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 80, 128)      0           dot_1[0][0]                      \n","                                                                 embedding_4[0][0]                \n","__________________________________________________________________________________________________\n","time_distributed_1 (TimeDistrib (None, 80, 64)       8256        concatenate[0][0]                \n","__________________________________________________________________________________________________\n","time_distributed_2 (TimeDistrib (None, 80, 46)       2990        time_distributed_1[0][0]         \n","==================================================================================================\n","Total params: 17,134\n","Trainable params: 17,134\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EKFfXvm52iDf","colab_type":"code","colab":{}},"source":["training_encoder_input = encoded_training_input\n","training_decoder_input = np.zeros_like(encoded_training_output)\n","training_decoder_input[:, 1:] = encoded_training_output[:,:-1]\n","training_decoder_input[:, 0] = START_CHAR_CODE\n","training_decoder_output = np.eye(reply_dict_size)[encoded_training_output.astype('int')]\n","\n","validation_encoder_input = encoded_validation_input\n","validation_decoder_input = np.zeros_like(encoded_validation_output)\n","validation_decoder_input[:, 1:] = encoded_validation_output[:,:-1]\n","validation_decoder_input[:, 0] = START_CHAR_CODE\n","validation_decoder_output = np.eye(reply_dict_size)[encoded_validation_output.astype('int')]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eG10rz444MCa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":714},"outputId":"5a99f38c-70a9-46f6-bba6-b7e391a8f2a5","executionInfo":{"status":"ok","timestamp":1571540278911,"user_tz":-330,"elapsed":160715,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}}},"source":["if os.path.isfile('model.h5'):\n","    model = load_model('model.h5')\n","else:\n","    model.fit(x=[training_encoder_input, training_decoder_input], y=[training_decoder_output],\n","          validation_data=([validation_encoder_input, validation_decoder_input], [validation_decoder_output]),\n","          verbose=2, batch_size=64, epochs=20)\n","\n","# model.fit(x=[training_encoder_input, training_decoder_input], y=[training_decoder_output],\n","#           validation_data=([validation_encoder_input, validation_decoder_input], [validation_decoder_output]),\n","#           verbose=2, batch_size=64, epochs=5)\n","\n","model.save('model.h5')"],"execution_count":75,"outputs":[{"output_type":"stream","text":["Train on 51428 samples, validate on 12857 samples\n","Epoch 1/20\n","51428/51428 - 13s - loss: 1.0807 - val_loss: 1.0584\n","Epoch 2/20\n","51428/51428 - 8s - loss: 1.0259 - val_loss: 1.0548\n","Epoch 3/20\n","51428/51428 - 8s - loss: 1.0238 - val_loss: 1.0534\n","Epoch 4/20\n","51428/51428 - 8s - loss: 1.0230 - val_loss: 1.0528\n","Epoch 5/20\n","51428/51428 - 8s - loss: 1.0225 - val_loss: 1.0526\n","Epoch 6/20\n","51428/51428 - 8s - loss: 1.0222 - val_loss: 1.0522\n","Epoch 7/20\n","51428/51428 - 8s - loss: 1.0220 - val_loss: 1.0520\n","Epoch 8/20\n","51428/51428 - 8s - loss: 1.0218 - val_loss: 1.0520\n","Epoch 9/20\n","51428/51428 - 8s - loss: 1.0216 - val_loss: 1.0521\n","Epoch 10/20\n","51428/51428 - 8s - loss: 1.0215 - val_loss: 1.0519\n","Epoch 11/20\n","51428/51428 - 8s - loss: 1.0214 - val_loss: 1.0518\n","Epoch 12/20\n","51428/51428 - 8s - loss: 1.0213 - val_loss: 1.0516\n","Epoch 13/20\n","51428/51428 - 8s - loss: 1.0211 - val_loss: 1.0515\n","Epoch 14/20\n","51428/51428 - 8s - loss: 1.0210 - val_loss: 1.0515\n","Epoch 15/20\n","51428/51428 - 8s - loss: 1.0209 - val_loss: 1.0513\n","Epoch 16/20\n","51428/51428 - 8s - loss: 1.0208 - val_loss: 1.0514\n","Epoch 17/20\n","51428/51428 - 8s - loss: 1.0208 - val_loss: 1.0514\n","Epoch 18/20\n","51428/51428 - 8s - loss: 1.0207 - val_loss: 1.0513\n","Epoch 19/20\n","51428/51428 - 8s - loss: 1.0206 - val_loss: 1.0511\n","Epoch 20/20\n","51428/51428 - 8s - loss: 1.0205 - val_loss: 1.0510\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9NKaR6id4MIA","colab_type":"code","colab":{}},"source":["def generate_katakana_sequence(text):\n","    encoder_input = transform(statement_encoding, [text.lower()], 80)\n","    decoder_input = np.zeros(shape=(len(encoder_input), OUTPUT_LENGTH))\n","    decoder_input[:,0] = START_CHAR_CODE\n","    for i in range(1, OUTPUT_LENGTH):\n","        output = model.predict([encoder_input, decoder_input]).argmax(axis=2)\n","        decoder_input[:,i] = output[:,i]\n","    return decoder_input[0, 1:]\n","\n","def decode(decoding, sequence):\n","    text = ''\n","    for i in sequence:\n","        if i == 0:\n","            break\n","        text += decoding[i]\n","    return text\n","\n","def to_katakana(text):\n","    decoder_output = generate_katakana_sequence(text)\n","    return decode(reply_decoding, decoder_output)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Js57jF5D4MOs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"182e2d14-2924-4442-b6cb-c1b1c748aa65","executionInfo":{"status":"ok","timestamp":1571540796168,"user_tz":-330,"elapsed":950,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}}},"source":["to_katakana('Banana')"],"execution_count":86,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'                                                                               '"]},"metadata":{"tags":[]},"execution_count":86}]},{"cell_type":"code","metadata":{"id":"un3sXBILIC3H","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ePqrMoWrIC-4","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SmLGON1GIDKK","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kO3HJXaYIDfN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z8X4d_t5IDmd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JtCXP2j5IDtk","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5oWIRj5_ID0i","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vxQqRwgsID7V","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fovm5kggIECX","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gS_ZDDvjIkos","colab_type":"text"},"source":["# Below pieces are part of some other notebook. Ignore"]},{"cell_type":"code","metadata":{"id":"swuzt1VyRXO3","colab_type":"code","colab":{}},"source":["input_texts, target_texts = [], []\n","input_vocabulary = set()\n","output_vocabulary = set()\n","start_token = '\\t'\n","stop_token = '\\n'\n","max_training_samples = min(25000, len(df) -1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"011FU8f_IfWC","colab_type":"code","colab":{}},"source":["for input_text, target_text in zip(df.statement, df.reply):\n","  target_text = start_token + target_text + stop_token\n","  input_texts.append(input_text)\n","  target_texts.append(target_text)\n","  for char in input_text:\n","    input_vocabulary.add(char)\n","  for char in target_text:\n","    output_vocabulary.add(char) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fg4G4YEgIfk2","colab_type":"code","colab":{}},"source":["input_vocabulary = sorted(input_vocabulary)\n","output_vocabulary = sorted(output_vocabulary)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M_x839TXR8jm","colab_type":"code","colab":{}},"source":["input_vocab_size = len(input_vocabulary)\n","output_vocab_size = len(output_vocabulary)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n8rHGRSXR8lp","colab_type":"code","colab":{}},"source":["max_encoder_seq_length = max([len(txt) for txt in input_texts])\n","max_decoder_seq_length = max([len(txt) for txt in target_texts])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZSn59RrkR8oA","colab_type":"code","colab":{}},"source":["input_char_index = dict((c,i) for i,c in enumerate(input_vocabulary))\n","target_char_index = dict((c,i) for i,c in enumerate(output_vocabulary))\n","\n","reverse_input_char_index = dict((i, c) for c, i in input_char_index.items())\n","reverse_target_char_index = dict((i, c) for c, i in target_char_index.items())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NEfR85y_VqTz","colab_type":"code","colab":{}},"source":["import numpy as np\n","encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, input_vocab_size), dtype = 'float32')\n","decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, output_vocab_size), dtype = 'float32')\n","decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, output_vocab_size), dtype='float32')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dWTjOgpauPyn","colab_type":"code","outputId":"4e6782ff-6bcf-43f1-d39b-da31b8abcebf","executionInfo":{"status":"ok","timestamp":1571399753755,"user_tz":300,"elapsed":550,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["encoder_input_data.reshape()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(100, 44)"]},"metadata":{"tags":[]},"execution_count":250}]},{"cell_type":"code","metadata":{"id":"hNXfHc5eR8p7","colab_type":"code","colab":{}},"source":["for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n","  for t,c in enumerate(input_text):\n","    encoder_input_data[i, t, input_char_index[c]] = 1.\n","  for t,c in enumerate(target_text):\n","    decoder_input_data[i, t, target_char_index[c]] = 1.\n","    if t > 0:\n","      decoder_target_data[i, t-1, target_char_index[c]] = 1."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JBDBM1jvQHas","colab_type":"code","outputId":"be7cdf00-a6b5-4c6d-fda5-a8901249bc6a","executionInfo":{"status":"ok","timestamp":1571401861318,"user_tz":300,"elapsed":1689,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import numpy as np  \n","import pandas as pd \n","import re           \n","from bs4 import BeautifulSoup \n","from keras.preprocessing.text import Tokenizer \n","from keras.preprocessing.sequence import pad_sequences\n","from nltk.corpus import stopwords  \n","import nltk\n","nltk.download('stopwords') \n","from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional, GRU\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import EarlyStopping\n","import warnings\n","pd.set_option(\"display.max_colwidth\", 200)\n","warnings.filterwarnings(\"ignore\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8vxuAeFfXTOh","colab_type":"code","outputId":"cfaa602d-1f87-4580-dc02-1ebeb9ba68e0","executionInfo":{"status":"ok","timestamp":1571370090495,"user_tz":-330,"elapsed":1476,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["encoder_inputs.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(None), Dimension(None), Dimension(100), Dimension(44)])"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"eIQsFLRfybTB","colab_type":"code","outputId":"451f5fdf-0eb4-4d2b-9b2b-3cee5b859826","executionInfo":{"status":"ok","timestamp":1571367450681,"user_tz":-330,"elapsed":1521,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["enc_emb.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(None), Dimension(44), Dimension(512)])"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"n7yZpwJeybZs","colab_type":"code","outputId":"4de45dfc-35e2-4618-bea1-d4a349b901d7","executionInfo":{"status":"ok","timestamp":1571381599768,"user_tz":-330,"elapsed":1332,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["encoder_input_data.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(64350, 100, 44)"]},"metadata":{"tags":[]},"execution_count":123}]},{"cell_type":"code","metadata":{"id":"lIEGhTOOybfJ","colab_type":"code","outputId":"f594df40-17b5-4624-e662-2794f64ef380","executionInfo":{"status":"ok","timestamp":1571369545977,"user_tz":-330,"elapsed":1111,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["enc_emb.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(None), Dimension(44), Dimension(512)])"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"eC-YVD9JybXF","colab_type":"code","outputId":"f0db44ad-b808-421d-a76b-99e3bc75f419","executionInfo":{"status":"ok","timestamp":1571372088287,"user_tz":-330,"elapsed":978,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["input_vocab_size"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["44"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"id":"SPca1qC1pIbK","colab_type":"code","outputId":"6c50408c-583b-48f8-d8e0-6d6311aeea99","executionInfo":{"status":"ok","timestamp":1571381615598,"user_tz":-330,"elapsed":1243,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["max_decoder_seq_length"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["102"]},"metadata":{"tags":[]},"execution_count":124}]},{"cell_type":"code","metadata":{"id":"RTRU4-QQTxkC","colab_type":"code","outputId":"994b65a5-62ac-4dd1-b7cd-3c855af10511","executionInfo":{"status":"ok","timestamp":1571376232816,"user_tz":-330,"elapsed":1236,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["encoder_inputs.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(64), Dimension(100), Dimension(44)])"]},"metadata":{"tags":[]},"execution_count":66}]},{"cell_type":"code","metadata":{"id":"ozB96N5fVQFh","colab_type":"code","outputId":"e49772bd-e4da-4479-e99c-f6ba6eee60c7","executionInfo":{"status":"ok","timestamp":1571376406189,"user_tz":-330,"elapsed":1537,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["decoder_inputs.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(64), Dimension(102), Dimension(46)])"]},"metadata":{"tags":[]},"execution_count":69}]},{"cell_type":"code","metadata":{"id":"s8QtFopBdKlT","colab_type":"code","outputId":"60fee6a6-dcb1-4aab-ed87-71d1e35f2209","executionInfo":{"status":"ok","timestamp":1571392519546,"user_tz":300,"elapsed":1202,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["encoder_outputs.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(64), Dimension(100), Dimension(512)])"]},"metadata":{"tags":[]},"execution_count":154}]},{"cell_type":"code","metadata":{"id":"LGuDOeBkdUwy","colab_type":"code","outputId":"63cb5b31-1302-46d5-834e-0f8efa938f85","executionInfo":{"status":"ok","timestamp":1571392514152,"user_tz":300,"elapsed":590,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["decoder_outputs.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(64), Dimension(102), Dimension(512)])"]},"metadata":{"tags":[]},"execution_count":153}]},{"cell_type":"code","metadata":{"id":"0wr30hcneUrC","colab_type":"code","outputId":"46beecc2-3894-4dbc-97a8-e6824164550a","executionInfo":{"status":"ok","timestamp":1571382206391,"user_tz":-330,"elapsed":1166,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["attn_out.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(64), Dimension(None), Dimension(512)])"]},"metadata":{"tags":[]},"execution_count":134}]},{"cell_type":"code","metadata":{"id":"ORAX9SP_Q7Fs","colab_type":"code","outputId":"c0766c26-d76a-4ff9-ef3a-cdca0e19a965","executionInfo":{"status":"ok","timestamp":1571392387557,"user_tz":300,"elapsed":540,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["attn_out.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(64), Dimension(None), Dimension(512)])"]},"metadata":{"tags":[]},"execution_count":151}]},{"cell_type":"code","metadata":{"id":"ZjYRO8q8Q7Iz","colab_type":"code","outputId":"9f4bd0a3-f466-4f1a-9a5b-9afe00f4ed2e","executionInfo":{"status":"ok","timestamp":1571392052437,"user_tz":300,"elapsed":587,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["output_vocab_size"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["46"]},"metadata":{"tags":[]},"execution_count":148}]},{"cell_type":"code","metadata":{"id":"DrslC5AbTxgx","colab_type":"code","outputId":"ac250dcd-210d-4427-a60a-7cd3950b3d34","executionInfo":{"status":"ok","timestamp":1571395940200,"user_tz":300,"elapsed":1868,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":459}},"source":["# from keras.models import Model\n","# from keras.layers import Input, LSTM, Dense\n","from keras import backend as K \n","K.clear_session() \n","batch_size = 64\n","epochs = 100\n","num_neurons = 512\n","\n","encoder_inputs = Input(batch_shape=(batch_size, max_encoder_seq_length, input_vocab_size))\n","decoder_inputs = Input(batch_shape=(batch_size, max_decoder_seq_length, output_vocab_size))\n","\n","encoder_lstm1 = LSTM(num_neurons, return_sequences=True, return_state=True, name='encoder_lstm1')\n","encoder_outputs, state_h, state_c = encoder_lstm1(encoder_inputs)\n","\n","decoder_lstm1 = LSTM(num_neurons, return_sequences=True, return_state=True, name='decoder_lstm1')\n","decoder_outputs,decoder_fwd_state,decoder_back_state = decoder_lstm1(decoder_inputs,initial_state=[state_h, state_c]) \n","\n","attn_layer = AttentionLayer(name='attention_layer') \n","attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n","\n","# Concat attention output and decoder LSTM output \n","decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n","\n","#Dense layer\n","dense = Dense(output_vocab_size, activation='softmax', name='softmax_layer')\n","decoder_time = TimeDistributed(dense, name = 'time_distributed_layer') \n","decoder_pred = decoder_time(decoder_concat_input) \n","\n","# Define the model\n","model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_pred) \n","model.summary()\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(64, 100, 44)]      0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(64, 102, 46)]      0                                            \n","__________________________________________________________________________________________________\n","encoder_lstm1 (LSTM)            [(64, 100, 512), (64 1140736     input_1[0][0]                    \n","__________________________________________________________________________________________________\n","decoder_lstm1 (LSTM)            [(64, 102, 512), (64 1144832     input_2[0][0]                    \n","                                                                 encoder_lstm1[0][1]              \n","                                                                 encoder_lstm1[0][2]              \n","__________________________________________________________________________________________________\n","attention_layer (AttentionLayer ((64, None, 512), (6 524800      encoder_lstm1[0][0]              \n","                                                                 decoder_lstm1[0][0]              \n","__________________________________________________________________________________________________\n","concat_layer (Concatenate)      (64, None, 512)      0           decoder_lstm1[0][0]              \n","                                                                 attention_layer[0][0]            \n","__________________________________________________________________________________________________\n","time_distributed_layer (TimeDis (None, None, 46)     23598       concat_layer[0][0]               \n","==================================================================================================\n","Total params: 2,833,966\n","Trainable params: 2,833,966\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IDHvUpgFTq5X","colab_type":"code","outputId":"f4739f71-f1a4-4f9b-8922-e7eb96ccd102","executionInfo":{"status":"ok","timestamp":1571400068124,"user_tz":300,"elapsed":696,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["encoder_inputs.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(None), Dimension(100), Dimension(44)])"]},"metadata":{"tags":[]},"execution_count":254}]},{"cell_type":"code","metadata":{"id":"9b8gds3IUIF4","colab_type":"code","outputId":"33f9cf50-f9b1-412a-9acf-256067d89583","executionInfo":{"status":"ok","timestamp":1571397110630,"user_tz":300,"elapsed":1198,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["enc_emb.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(None), Dimension(100), Dimension(512)])"]},"metadata":{"tags":[]},"execution_count":237}]},{"cell_type":"code","metadata":{"id":"ALQUv8sDUMR3","colab_type":"code","outputId":"c7b50a41-7995-4e91-cb68-bfae3fe4c52d","executionInfo":{"status":"ok","timestamp":1571397232334,"user_tz":300,"elapsed":536,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["encoder_outputs.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(None), Dimension(100), Dimension(512)])"]},"metadata":{"tags":[]},"execution_count":238}]},{"cell_type":"code","metadata":{"id":"3HtxN9UOUeOE","colab_type":"code","outputId":"314115b4-4a6a-4ae1-f62a-2d91972ac060","executionInfo":{"status":"ok","timestamp":1571400776398,"user_tz":300,"elapsed":614,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["decoder_inputs.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(None), Dimension(None), Dimension(None)])"]},"metadata":{"tags":[]},"execution_count":273}]},{"cell_type":"code","metadata":{"id":"Pb7pdCmnZsmB","colab_type":"code","outputId":"d4a5ea04-fab0-4bb3-c32a-09dc34e87f18","executionInfo":{"status":"ok","timestamp":1571397292977,"user_tz":300,"elapsed":548,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["dec_emb.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(None), Dimension(None), Dimension(512)])"]},"metadata":{"tags":[]},"execution_count":241}]},{"cell_type":"code","metadata":{"id":"beUiZyDncZVo","colab_type":"code","outputId":"669cad46-4cae-4ee5-fd8b-1d0e505bfba9","executionInfo":{"status":"ok","timestamp":1571395721892,"user_tz":300,"elapsed":538,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["decoder_inputs.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(None), Dimension(None), Dimension(46)])"]},"metadata":{"tags":[]},"execution_count":219}]},{"cell_type":"code","metadata":{"id":"neCVogNweft8","colab_type":"code","outputId":"1f840397-8c46-4e78-ee5a-9062a9acaa01","executionInfo":{"status":"ok","timestamp":1571397352822,"user_tz":300,"elapsed":546,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["decoder_outputs.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(None), Dimension(None), Dimension(512)])"]},"metadata":{"tags":[]},"execution_count":243}]},{"cell_type":"code","metadata":{"id":"Z_II1uN3lhhe","colab_type":"code","outputId":"cda4e475-8f9e-4223-ae84-b3d9608a21b2","executionInfo":{"status":"ok","timestamp":1571397445377,"user_tz":300,"elapsed":547,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["attn_out.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(None), Dimension(None), Dimension(512)])"]},"metadata":{"tags":[]},"execution_count":245}]},{"cell_type":"code","metadata":{"id":"vof1Rj1ogsKE","colab_type":"code","outputId":"fa51ebdc-b943-42e0-a5b5-910329944585","executionInfo":{"status":"error","timestamp":1571401135086,"user_tz":300,"elapsed":1240,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":376}},"source":["# from keras.models import Model\n","# from keras.layers import Input, LSTM, Dense\n","from keras import backend as K \n","K.clear_session() \n","batch_size = 64\n","epochs = 100\n","num_neurons = 512\n","\n","\n","# Encoder \n","encoder_inputs = Input(shape=(max_encoder_seq_length,input_vocab_size,)) \n","# enc_emb = Embedding(input_vocab_size, num_neurons,trainable=True)(encoder_inputs) \n","\n","#LSTM 1 \n","encoder_lstm1 = LSTM(num_neurons,return_sequences=True,return_state=True) \n","encoder_outputs, state_h, state_c = encoder_lstm1(encoder_inputs) \n","\n","# #LSTM 2 \n","# encoder_lstm2 = LSTM(num_neurons,return_sequences=True,return_state=True) \n","# encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n","\n","# #LSTM 3 \n","# encoder_lstm3=LSTM(num_neurons, return_state=True, return_sequences=True) \n","# encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n","\n","# Set up the decoder. \n","decoder_inputs = Input(shape=(max_decoder_seq_length, output_vocab_size)) \n","# dec_emb_layer = Embedding(output_vocab_size, num_neurons, trainable=True) \n","# dec_emb = dec_emb_layer(decoder_inputs) \n","\n","#LSTM using encoder_states as initial state\n","decoder_lstm = LSTM(num_neurons, return_sequences=True, return_state=True) \n","decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(decoder_inputs,initial_state=[state_h, state_c]) \n","\n","#Attention Layer\n","attn_layer = AttentionLayer(name='attention_layer') \n","attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n","\n","# Concat attention output and decoder LSTM output \n","decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n","\n","#Dense layer\n","decoder_dense = TimeDistributed(Dense(output_vocab_size, activation='softmax')) \n","decoder_pred = decoder_dense(decoder_concat_input) \n","\n","# Define the model\n","model = Model([encoder_inputs, decoder_inputs], decoder_pred) \n","model.summary()\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-276-80c504859e13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Concat attention output and decoder LSTM output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mdecoder_concat_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'concat_layer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_out\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#Dense layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m       \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m       \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    389\u001b[0m                        \u001b[0;34m'inputs with matching shapes '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                        \u001b[0;34m'except for the concat axis. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                        'Got inputs shapes: %s' % (input_shape))\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 102, 512), (None, None, 512)]"]}]},{"cell_type":"code","metadata":{"id":"EP41AdcHgRq2","colab_type":"code","outputId":"11820813-0d38-4b23-8af3-cc1296bbced6","executionInfo":{"status":"error","timestamp":1571402076137,"user_tz":300,"elapsed":4401,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":495}},"source":["model = Model([encoder_inputs, decoder_inputs], decoder_pred)\n","model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n","model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size = batch_size, epochs = epochs, validation_split=0.1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 57915 samples, validate on 6435 samples\n","Epoch 1/100\n"],"name":"stdout"},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-281-bf1eac7e45c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_inputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_input_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_target_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument: Incompatible shapes: [64,102] vs. [64,204]\n\t [[{{node metrics/acc/Equal}}]]\n\t [[loss/mul/_101]]\n  (1) Invalid argument: Incompatible shapes: [64,102] vs. [64,204]\n\t [[{{node metrics/acc/Equal}}]]\n0 successful operations.\n0 derived errors ignored."]}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"0deb58fb-ff0d-4312-87a0-9672ab73a0af","executionInfo":{"status":"ok","timestamp":1571402046736,"user_tz":300,"elapsed":1224,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"id":"mBXfoLxfqxSi","colab":{"base_uri":"https://localhost:8080/","height":442}},"source":["from keras import backend as K \n","K.clear_session() \n","batch_size = 64\n","epochs = 100\n","num_neurons = 512\n","\n","encoder_inputs = Input(batch_shape=(batch_size, max_encoder_seq_length, input_vocab_size))\n","decoder_inputs = Input(batch_shape=(batch_size, max_decoder_seq_length, output_vocab_size))\n","\n","encoder_gru = GRU(num_neurons, return_sequences=True, return_state=True, name='encoder_gru')\n","encoder_outputs, encoder_state = encoder_gru(encoder_inputs)\n","\n","decoder_gru = GRU(num_neurons, return_sequences=True, return_state=True, name='decoder_gru')\n","decoder_outputs,decoder_state = decoder_gru(decoder_inputs,initial_state= encoder_state) \n","\n","attn_layer = AttentionLayer(name='attention_layer') \n","attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n","\n","# Concat attention output and decoder LSTM output \n","decoder_concat_input = Concatenate(axis=1, name='concat_layer')([decoder_outputs, attn_out])\n","\n","#Dense layer\n","dense = Dense(output_vocab_size, activation='softmax', name='softmax_layer')\n","decoder_time = TimeDistributed(dense, name = 'time_distributed_layer') \n","decoder_pred = decoder_time(decoder_concat_input) \n","\n","# Define the model\n","model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_pred) \n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(64, 100, 44)]      0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(64, 102, 46)]      0                                            \n","__________________________________________________________________________________________________\n","encoder_gru (GRU)               [(64, 100, 512), (64 855552      input_1[0][0]                    \n","__________________________________________________________________________________________________\n","decoder_gru (GRU)               [(64, 102, 512), (64 858624      input_2[0][0]                    \n","                                                                 encoder_gru[0][1]                \n","__________________________________________________________________________________________________\n","attention_layer (AttentionLayer ((64, None, 512), (6 524800      encoder_gru[0][0]                \n","                                                                 decoder_gru[0][0]                \n","__________________________________________________________________________________________________\n","concat_layer (Concatenate)      (64, None, 512)      0           decoder_gru[0][0]                \n","                                                                 attention_layer[0][0]            \n","__________________________________________________________________________________________________\n","time_distributed_layer (TimeDis (None, None, 46)     23598       concat_layer[0][0]               \n","==================================================================================================\n","Total params: 2,262,574\n","Trainable params: 2,262,574\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nKwukuqvY6MW","colab_type":"code","outputId":"eba47d53-3fab-4aa5-8ddb-2d4f98aafe68","executionInfo":{"status":"ok","timestamp":1571381741592,"user_tz":-330,"elapsed":1312,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["encoder_input_data.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(64350, 100, 44)"]},"metadata":{"tags":[]},"execution_count":126}]},{"cell_type":"code","metadata":{"id":"Hg6-XRDOR8y4","colab_type":"code","colab":{}},"source":["# Assemble the model for sequence generation\n","encoder_model = Model(encoder_inputs, encoder_states)\n","thought_input = [Input(shape=(num_neurons,)), Input(shape=(num_neurons,))]\n","decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=thought_input)\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","decoder_model = Model(inputs=[decoder_inputs] + thought_input,\n","                     outputs=[decoder_outputs] + decoder_states)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IVFC0o7zR805","colab_type":"code","colab":{}},"source":["# Build a character-based translator \n","def decode_sequence(input_seq):\n","  thought = encoder_model.predict(input_seq)\n","  \n","  target_seq = np.zeros((1,1,output_vocab_size))\n","  target_seq[0, 0, target_token_index[start_token]] = 1.\n","  stop_condition = False\n","  generated_sequence = ''\n","  \n","  while not stop_condition:\n","    output_tokens, h, c = decoder_model.predict([target_seq] + thought)\n","    generated_token_idx = np.argmax(output_tokens[0, -1, :])\n","    generated_char = reverse_target_char_index[generated_token_idx]\n","    generated_sequence += generated_char\n","    if (generated_char == stop_token or len(generated_sequence) > max_decoder_seq_length):\n","      stop_condition = True\n","    target_seq = np.zeros((1, 1, output_vocab_size))\n","    target_seq[0, 0, generated_token_idx] = 1.\n","    thought = [h, c]\n","  return generated_sequence"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AISNouHMR83P","colab_type":"code","colab":{}},"source":["# Generating a response\n","def response(input_text):\n","  input_seq = np.zeros((1, max_encoder_seq_length, input_vocab_size), dtype='float32')\n","  for t, char in enumerate(input_text):\n","    input_seq[0, t, input_token_index[char]] = 1.\n","  decoded_sentence = decode_sequence(input_seq)\n","  print('Bot Reply (Decoded sentence):', decoded_sentence)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gueEuDuuR85T","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mkyaTYO7R87w","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MEM04xPnR8-c","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ax1B8u-fR8t_","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M0YpQpUrR8sG","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XPJJ6re4IfnY","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CgdoOce7Ifqj","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2zdnTnjcIftd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4xz4oDivIfwN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MttpSq_bIfze","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ESaDvRSmIf2P","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zk-vOkdjIf8S","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Bkv5Ut0If_d","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MaCeaWgpIgCY","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"siaxngVwIgFK","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f7G4WwGBIf5T","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}