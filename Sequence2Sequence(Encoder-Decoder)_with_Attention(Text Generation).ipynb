{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sequence2Sequence(Encoder-Decoder)_with_Attention(Text Generation).ipynb","provenance":[{"file_id":"1WdCWabSymMfhOJK1ejzzUVgkIpflCxtn","timestamp":1571323202479}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"53xgu7v-XMEo","colab_type":"code","outputId":"6a10a2b0-a9f3-4cd0-80f6-79c5e79d3ece","executionInfo":{"status":"ok","timestamp":1571485001792,"user_tz":-330,"elapsed":22272,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rB2QmaGgIJG6","colab_type":"code","outputId":"c0820a18-7fa3-41c6-d982-f548b6b1cea8","executionInfo":{"status":"ok","timestamp":1571485028417,"user_tz":-330,"elapsed":9401,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["!git clone https://github.com/totalgood/nlpia.git"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Cloning into 'nlpia'...\n","remote: Enumerating objects: 196, done.\u001b[K\n","remote: Counting objects: 100% (196/196), done.\u001b[K\n","remote: Compressing objects: 100% (118/118), done.\u001b[K\n","remote: Total 5827 (delta 98), reused 138 (delta 57), pack-reused 5631\u001b[K\n","Receiving objects: 100% (5827/5827), 124.02 MiB | 27.05 MiB/s, done.\n","Resolving deltas: 100% (3674/3674), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3FXYYs2FIpJU","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mDJryqyGIfIi","colab_type":"code","colab":{}},"source":["df = pd.read_csv('/content/nlpia/src/nlpia/data/moviedialog.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZCWX8-97IfMZ","colab_type":"code","colab":{}},"source":["df.drop(columns='Unnamed: 0', axis=1,inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QPzSUj5PIfPv","colab_type":"code","outputId":"e06677f4-c65e-45b9-f597-0342f70a83f0","executionInfo":{"status":"ok","timestamp":1571485364293,"user_tz":-330,"elapsed":1197,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["df.head(5)"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>statement</th>\n","      <th>reply</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>you're asking me out. that's so cute. what's y...</td>\n","      <td>forget it.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>no, no, it's my fault we didn't have a proper ...</td>\n","      <td>cameron.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>gosh, if only we could find kat a boyfriend...</td>\n","      <td>let me see what i can do.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>c'esc ma tete. this is my head</td>\n","      <td>right. see? you're ready for the quiz.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>how is our little find the wench a date plan p...</td>\n","      <td>well, there's someone i think might be</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                           statement                                    reply\n","0  you're asking me out. that's so cute. what's y...                               forget it.\n","1  no, no, it's my fault we didn't have a proper ...                                 cameron.\n","2     gosh, if only we could find kat a boyfriend...                let me see what i can do.\n","3                     c'esc ma tete. this is my head   right. see? you're ready for the quiz.\n","4  how is our little find the wench a date plan p...  well, there's someone i think might be "]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"kiYcCvtjP8Mk","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import os\n","from tensorflow.python.keras.layers import Layer\n","from tensorflow.python.keras import backend as K\n","\n","\n","class AttentionLayer(Layer):\n","    \"\"\"\n","    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n","    There are three sets of weights introduced W_a, U_a, and V_a\n","     \"\"\"\n","\n","    def __init__(self, **kwargs):\n","        super(AttentionLayer, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        assert isinstance(input_shape, list)\n","        # Create a trainable weight variable for this layer.\n","\n","        self.W_a = self.add_weight(name='W_a',\n","                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n","                                   initializer='uniform',\n","                                   trainable=True)\n","        self.U_a = self.add_weight(name='U_a',\n","                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n","                                   initializer='uniform',\n","                                   trainable=True)\n","        self.V_a = self.add_weight(name='V_a',\n","                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n","                                   initializer='uniform',\n","                                   trainable=True)\n","\n","        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n","\n","    def call(self, inputs, verbose=False):\n","        \"\"\"\n","        inputs: [encoder_output_sequence, decoder_output_sequence]\n","        \"\"\"\n","        assert type(inputs) == list\n","        encoder_out_seq, decoder_out_seq = inputs\n","        if verbose:\n","            print('encoder_out_seq>', encoder_out_seq.shape)\n","            print('decoder_out_seq>', decoder_out_seq.shape)\n","\n","        def energy_step(inputs, states):\n","            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n","\n","            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n","            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n","\n","            \"\"\" Some parameters required for shaping tensors\"\"\"\n","            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n","            de_hidden = inputs.shape[-1]\n","\n","            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n","            # <= batch_size*en_seq_len, latent_dim\n","            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n","            # <= batch_size*en_seq_len, latent_dim\n","            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n","            if verbose:\n","                print('wa.s>',W_a_dot_s.shape)\n","\n","            \"\"\" Computing hj.Ua \"\"\"\n","            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n","            if verbose:\n","                print('Ua.h>',U_a_dot_h.shape)\n","\n","            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n","            # <= batch_size*en_seq_len, latent_dim\n","            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n","            if verbose:\n","                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n","\n","            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n","            # <= batch_size, en_seq_len\n","            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n","            # <= batch_size, en_seq_len\n","            e_i = K.softmax(e_i)\n","\n","            if verbose:\n","                print('ei>', e_i.shape)\n","\n","            return e_i, [e_i]\n","\n","        def context_step(inputs, states):\n","            \"\"\" Step function for computing ci using ei \"\"\"\n","            # <= batch_size, hidden_size\n","            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n","            if verbose:\n","                print('ci>', c_i.shape)\n","            return c_i, [c_i]\n","\n","        def create_inital_state(inputs, hidden_size):\n","            # We are not using initial states, but need to pass something to K.rnn funciton\n","            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n","            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n","            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n","            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n","            return fake_state\n","\n","        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n","        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n","\n","        \"\"\" Computing energy outputs \"\"\"\n","        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n","        last_out, e_outputs, _ = K.rnn(\n","            energy_step, decoder_out_seq, [fake_state_e],\n","        )\n","\n","        \"\"\" Computing context vectors \"\"\"\n","        last_out, c_outputs, _ = K.rnn(\n","            context_step, e_outputs, [fake_state_c],\n","        )\n","\n","        return c_outputs, e_outputs\n","\n","    def compute_output_shape(self, input_shape):\n","        \"\"\" Outputs produced by the layer \"\"\"\n","        return [\n","            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n","            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n","        ]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aPabITAaLVDd","colab_type":"text"},"source":["# Preprocessing"]},{"cell_type":"code","metadata":{"id":"swuzt1VyRXO3","colab_type":"code","colab":{}},"source":["input_texts, target_texts = [], []\n","input_vocabulary = set()\n","output_vocabulary = set()\n","start_token = '\\t'\n","stop_token = '\\n'\n","max_training_samples = min(25000, len(df) -1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"011FU8f_IfWC","colab_type":"code","colab":{}},"source":["for input_text, target_text in zip(df.statement, df.reply):\n","  target_text = start_token + target_text + stop_token\n","  input_texts.append(input_text)\n","  target_texts.append(target_text)\n","  for char in input_text:\n","    input_vocabulary.add(char)\n","  for char in target_text:\n","    output_vocabulary.add(char) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fg4G4YEgIfk2","colab_type":"code","colab":{}},"source":["input_vocabulary = sorted(input_vocabulary)\n","output_vocabulary = sorted(output_vocabulary)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M_x839TXR8jm","colab_type":"code","colab":{}},"source":["input_vocab_size = len(input_vocabulary)\n","output_vocab_size = len(output_vocabulary)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n8rHGRSXR8lp","colab_type":"code","colab":{}},"source":["max_encoder_seq_length = max([len(txt) for txt in input_texts])\n","max_decoder_seq_length = max([len(txt) for txt in target_texts])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZSn59RrkR8oA","colab_type":"code","colab":{}},"source":["input_char_index = dict((c,i) for i,c in enumerate(input_vocabulary))\n","target_char_index = dict((c,i) for i,c in enumerate(output_vocabulary))\n","\n","reverse_input_char_index = dict((i, c) for c, i in input_char_index.items())\n","reverse_target_char_index = dict((i, c) for c, i in target_char_index.items())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NEfR85y_VqTz","colab_type":"code","colab":{}},"source":["import numpy as np\n","encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, input_vocab_size), dtype = 'float32')\n","decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, output_vocab_size), dtype = 'float32')\n","decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, output_vocab_size), dtype='float32')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dWTjOgpauPyn","colab_type":"code","outputId":"4e6782ff-6bcf-43f1-d39b-da31b8abcebf","executionInfo":{"status":"ok","timestamp":1571399753755,"user_tz":300,"elapsed":550,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["encoder_input_data.reshape()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(100, 44)"]},"metadata":{"tags":[]},"execution_count":250}]},{"cell_type":"code","metadata":{"id":"hNXfHc5eR8p7","colab_type":"code","colab":{}},"source":["for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n","  for t,c in enumerate(input_text):\n","    encoder_input_data[i, t, input_char_index[c]] = 1.\n","  for t,c in enumerate(target_text):\n","    decoder_input_data[i, t, target_char_index[c]] = 1.\n","    if t > 0:\n","      decoder_target_data[i, t-1, target_char_index[c]] = 1."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JBDBM1jvQHas","colab_type":"code","outputId":"be7cdf00-a6b5-4c6d-fda5-a8901249bc6a","executionInfo":{"status":"ok","timestamp":1571401861318,"user_tz":300,"elapsed":1689,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import numpy as np  \n","import pandas as pd \n","import re           \n","from bs4 import BeautifulSoup \n","from keras.preprocessing.text import Tokenizer \n","from keras.preprocessing.sequence import pad_sequences\n","from nltk.corpus import stopwords  \n","import nltk\n","nltk.download('stopwords') \n","from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional, GRU\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import EarlyStopping\n","import warnings\n","pd.set_option(\"display.max_colwidth\", 200)\n","warnings.filterwarnings(\"ignore\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8vxuAeFfXTOh","colab_type":"code","outputId":"cfaa602d-1f87-4580-dc02-1ebeb9ba68e0","executionInfo":{"status":"ok","timestamp":1571370090495,"user_tz":-330,"elapsed":1476,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["encoder_inputs.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(None), Dimension(None), Dimension(100), Dimension(44)])"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"eIQsFLRfybTB","colab_type":"code","outputId":"451f5fdf-0eb4-4d2b-9b2b-3cee5b859826","executionInfo":{"status":"ok","timestamp":1571367450681,"user_tz":-330,"elapsed":1521,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["enc_emb.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(None), Dimension(44), Dimension(512)])"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"n7yZpwJeybZs","colab_type":"code","outputId":"4de45dfc-35e2-4618-bea1-d4a349b901d7","executionInfo":{"status":"ok","timestamp":1571381599768,"user_tz":-330,"elapsed":1332,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["encoder_input_data.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(64350, 100, 44)"]},"metadata":{"tags":[]},"execution_count":123}]},{"cell_type":"code","metadata":{"id":"lIEGhTOOybfJ","colab_type":"code","outputId":"f594df40-17b5-4624-e662-2794f64ef380","executionInfo":{"status":"ok","timestamp":1571369545977,"user_tz":-330,"elapsed":1111,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["enc_emb.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(None), Dimension(44), Dimension(512)])"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"eC-YVD9JybXF","colab_type":"code","outputId":"f0db44ad-b808-421d-a76b-99e3bc75f419","executionInfo":{"status":"ok","timestamp":1571372088287,"user_tz":-330,"elapsed":978,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["input_vocab_size"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["44"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"id":"SPca1qC1pIbK","colab_type":"code","outputId":"6c50408c-583b-48f8-d8e0-6d6311aeea99","executionInfo":{"status":"ok","timestamp":1571381615598,"user_tz":-330,"elapsed":1243,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["max_decoder_seq_length"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["102"]},"metadata":{"tags":[]},"execution_count":124}]},{"cell_type":"code","metadata":{"id":"RTRU4-QQTxkC","colab_type":"code","outputId":"994b65a5-62ac-4dd1-b7cd-3c855af10511","executionInfo":{"status":"ok","timestamp":1571376232816,"user_tz":-330,"elapsed":1236,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["encoder_inputs.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(64), Dimension(100), Dimension(44)])"]},"metadata":{"tags":[]},"execution_count":66}]},{"cell_type":"code","metadata":{"id":"ozB96N5fVQFh","colab_type":"code","outputId":"e49772bd-e4da-4479-e99c-f6ba6eee60c7","executionInfo":{"status":"ok","timestamp":1571376406189,"user_tz":-330,"elapsed":1537,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["decoder_inputs.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(64), Dimension(102), Dimension(46)])"]},"metadata":{"tags":[]},"execution_count":69}]},{"cell_type":"code","metadata":{"id":"s8QtFopBdKlT","colab_type":"code","outputId":"60fee6a6-dcb1-4aab-ed87-71d1e35f2209","executionInfo":{"status":"ok","timestamp":1571392519546,"user_tz":300,"elapsed":1202,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["encoder_outputs.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(64), Dimension(100), Dimension(512)])"]},"metadata":{"tags":[]},"execution_count":154}]},{"cell_type":"code","metadata":{"id":"LGuDOeBkdUwy","colab_type":"code","outputId":"63cb5b31-1302-46d5-834e-0f8efa938f85","executionInfo":{"status":"ok","timestamp":1571392514152,"user_tz":300,"elapsed":590,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["decoder_outputs.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(64), Dimension(102), Dimension(512)])"]},"metadata":{"tags":[]},"execution_count":153}]},{"cell_type":"code","metadata":{"id":"0wr30hcneUrC","colab_type":"code","outputId":"46beecc2-3894-4dbc-97a8-e6824164550a","executionInfo":{"status":"ok","timestamp":1571382206391,"user_tz":-330,"elapsed":1166,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["attn_out.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(64), Dimension(None), Dimension(512)])"]},"metadata":{"tags":[]},"execution_count":134}]},{"cell_type":"code","metadata":{"id":"ORAX9SP_Q7Fs","colab_type":"code","outputId":"c0766c26-d76a-4ff9-ef3a-cdca0e19a965","executionInfo":{"status":"ok","timestamp":1571392387557,"user_tz":300,"elapsed":540,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["attn_out.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(64), Dimension(None), Dimension(512)])"]},"metadata":{"tags":[]},"execution_count":151}]},{"cell_type":"code","metadata":{"id":"ZjYRO8q8Q7Iz","colab_type":"code","outputId":"9f4bd0a3-f466-4f1a-9a5b-9afe00f4ed2e","executionInfo":{"status":"ok","timestamp":1571392052437,"user_tz":300,"elapsed":587,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["output_vocab_size"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["46"]},"metadata":{"tags":[]},"execution_count":148}]},{"cell_type":"code","metadata":{"id":"DrslC5AbTxgx","colab_type":"code","outputId":"ac250dcd-210d-4427-a60a-7cd3950b3d34","executionInfo":{"status":"ok","timestamp":1571395940200,"user_tz":300,"elapsed":1868,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":459}},"source":["# from keras.models import Model\n","# from keras.layers import Input, LSTM, Dense\n","from keras import backend as K \n","K.clear_session() \n","batch_size = 64\n","epochs = 100\n","num_neurons = 512\n","\n","encoder_inputs = Input(batch_shape=(batch_size, max_encoder_seq_length, input_vocab_size))\n","decoder_inputs = Input(batch_shape=(batch_size, max_decoder_seq_length, output_vocab_size))\n","\n","encoder_lstm1 = LSTM(num_neurons, return_sequences=True, return_state=True, name='encoder_lstm1')\n","encoder_outputs, state_h, state_c = encoder_lstm1(encoder_inputs)\n","\n","decoder_lstm1 = LSTM(num_neurons, return_sequences=True, return_state=True, name='decoder_lstm1')\n","decoder_outputs,decoder_fwd_state,decoder_back_state = decoder_lstm1(decoder_inputs,initial_state=[state_h, state_c]) \n","\n","attn_layer = AttentionLayer(name='attention_layer') \n","attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n","\n","# Concat attention output and decoder LSTM output \n","decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n","\n","#Dense layer\n","dense = Dense(output_vocab_size, activation='softmax', name='softmax_layer')\n","decoder_time = TimeDistributed(dense, name = 'time_distributed_layer') \n","decoder_pred = decoder_time(decoder_concat_input) \n","\n","# Define the model\n","model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_pred) \n","model.summary()\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(64, 100, 44)]      0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(64, 102, 46)]      0                                            \n","__________________________________________________________________________________________________\n","encoder_lstm1 (LSTM)            [(64, 100, 512), (64 1140736     input_1[0][0]                    \n","__________________________________________________________________________________________________\n","decoder_lstm1 (LSTM)            [(64, 102, 512), (64 1144832     input_2[0][0]                    \n","                                                                 encoder_lstm1[0][1]              \n","                                                                 encoder_lstm1[0][2]              \n","__________________________________________________________________________________________________\n","attention_layer (AttentionLayer ((64, None, 512), (6 524800      encoder_lstm1[0][0]              \n","                                                                 decoder_lstm1[0][0]              \n","__________________________________________________________________________________________________\n","concat_layer (Concatenate)      (64, None, 512)      0           decoder_lstm1[0][0]              \n","                                                                 attention_layer[0][0]            \n","__________________________________________________________________________________________________\n","time_distributed_layer (TimeDis (None, None, 46)     23598       concat_layer[0][0]               \n","==================================================================================================\n","Total params: 2,833,966\n","Trainable params: 2,833,966\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IDHvUpgFTq5X","colab_type":"code","outputId":"f4739f71-f1a4-4f9b-8922-e7eb96ccd102","executionInfo":{"status":"ok","timestamp":1571400068124,"user_tz":300,"elapsed":696,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["encoder_inputs.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(None), Dimension(100), Dimension(44)])"]},"metadata":{"tags":[]},"execution_count":254}]},{"cell_type":"code","metadata":{"id":"9b8gds3IUIF4","colab_type":"code","outputId":"33f9cf50-f9b1-412a-9acf-256067d89583","executionInfo":{"status":"ok","timestamp":1571397110630,"user_tz":300,"elapsed":1198,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["enc_emb.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(None), Dimension(100), Dimension(512)])"]},"metadata":{"tags":[]},"execution_count":237}]},{"cell_type":"code","metadata":{"id":"ALQUv8sDUMR3","colab_type":"code","outputId":"c7b50a41-7995-4e91-cb68-bfae3fe4c52d","executionInfo":{"status":"ok","timestamp":1571397232334,"user_tz":300,"elapsed":536,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["encoder_outputs.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(None), Dimension(100), Dimension(512)])"]},"metadata":{"tags":[]},"execution_count":238}]},{"cell_type":"code","metadata":{"id":"3HtxN9UOUeOE","colab_type":"code","outputId":"314115b4-4a6a-4ae1-f62a-2d91972ac060","executionInfo":{"status":"ok","timestamp":1571400776398,"user_tz":300,"elapsed":614,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["decoder_inputs.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(None), Dimension(None), Dimension(None)])"]},"metadata":{"tags":[]},"execution_count":273}]},{"cell_type":"code","metadata":{"id":"Pb7pdCmnZsmB","colab_type":"code","outputId":"d4a5ea04-fab0-4bb3-c32a-09dc34e87f18","executionInfo":{"status":"ok","timestamp":1571397292977,"user_tz":300,"elapsed":548,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["dec_emb.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(None), Dimension(None), Dimension(512)])"]},"metadata":{"tags":[]},"execution_count":241}]},{"cell_type":"code","metadata":{"id":"beUiZyDncZVo","colab_type":"code","outputId":"669cad46-4cae-4ee5-fd8b-1d0e505bfba9","executionInfo":{"status":"ok","timestamp":1571395721892,"user_tz":300,"elapsed":538,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["decoder_inputs.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(None), Dimension(None), Dimension(46)])"]},"metadata":{"tags":[]},"execution_count":219}]},{"cell_type":"code","metadata":{"id":"neCVogNweft8","colab_type":"code","outputId":"1f840397-8c46-4e78-ee5a-9062a9acaa01","executionInfo":{"status":"ok","timestamp":1571397352822,"user_tz":300,"elapsed":546,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["decoder_outputs.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(None), Dimension(None), Dimension(512)])"]},"metadata":{"tags":[]},"execution_count":243}]},{"cell_type":"code","metadata":{"id":"Z_II1uN3lhhe","colab_type":"code","outputId":"cda4e475-8f9e-4223-ae84-b3d9608a21b2","executionInfo":{"status":"ok","timestamp":1571397445377,"user_tz":300,"elapsed":547,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["attn_out.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(None), Dimension(None), Dimension(512)])"]},"metadata":{"tags":[]},"execution_count":245}]},{"cell_type":"code","metadata":{"id":"vof1Rj1ogsKE","colab_type":"code","outputId":"fa51ebdc-b943-42e0-a5b5-910329944585","executionInfo":{"status":"error","timestamp":1571401135086,"user_tz":300,"elapsed":1240,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":376}},"source":["# from keras.models import Model\n","# from keras.layers import Input, LSTM, Dense\n","from keras import backend as K \n","K.clear_session() \n","batch_size = 64\n","epochs = 100\n","num_neurons = 512\n","\n","\n","# Encoder \n","encoder_inputs = Input(shape=(max_encoder_seq_length,input_vocab_size,)) \n","# enc_emb = Embedding(input_vocab_size, num_neurons,trainable=True)(encoder_inputs) \n","\n","#LSTM 1 \n","encoder_lstm1 = LSTM(num_neurons,return_sequences=True,return_state=True) \n","encoder_outputs, state_h, state_c = encoder_lstm1(encoder_inputs) \n","\n","# #LSTM 2 \n","# encoder_lstm2 = LSTM(num_neurons,return_sequences=True,return_state=True) \n","# encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n","\n","# #LSTM 3 \n","# encoder_lstm3=LSTM(num_neurons, return_state=True, return_sequences=True) \n","# encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n","\n","# Set up the decoder. \n","decoder_inputs = Input(shape=(max_decoder_seq_length, output_vocab_size)) \n","# dec_emb_layer = Embedding(output_vocab_size, num_neurons, trainable=True) \n","# dec_emb = dec_emb_layer(decoder_inputs) \n","\n","#LSTM using encoder_states as initial state\n","decoder_lstm = LSTM(num_neurons, return_sequences=True, return_state=True) \n","decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(decoder_inputs,initial_state=[state_h, state_c]) \n","\n","#Attention Layer\n","attn_layer = AttentionLayer(name='attention_layer') \n","attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n","\n","# Concat attention output and decoder LSTM output \n","decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n","\n","#Dense layer\n","decoder_dense = TimeDistributed(Dense(output_vocab_size, activation='softmax')) \n","decoder_pred = decoder_dense(decoder_concat_input) \n","\n","# Define the model\n","model = Model([encoder_inputs, decoder_inputs], decoder_pred) \n","model.summary()\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-276-80c504859e13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Concat attention output and decoder LSTM output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mdecoder_concat_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'concat_layer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_out\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#Dense layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m       \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m       \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    389\u001b[0m                        \u001b[0;34m'inputs with matching shapes '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                        \u001b[0;34m'except for the concat axis. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                        'Got inputs shapes: %s' % (input_shape))\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 102, 512), (None, None, 512)]"]}]},{"cell_type":"code","metadata":{"id":"EP41AdcHgRq2","colab_type":"code","outputId":"11820813-0d38-4b23-8af3-cc1296bbced6","executionInfo":{"status":"error","timestamp":1571402076137,"user_tz":300,"elapsed":4401,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":495}},"source":["model = Model([encoder_inputs, decoder_inputs], decoder_pred)\n","model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n","model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size = batch_size, epochs = epochs, validation_split=0.1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 57915 samples, validate on 6435 samples\n","Epoch 1/100\n"],"name":"stdout"},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-281-bf1eac7e45c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_inputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_input_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_target_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument: Incompatible shapes: [64,102] vs. [64,204]\n\t [[{{node metrics/acc/Equal}}]]\n\t [[loss/mul/_101]]\n  (1) Invalid argument: Incompatible shapes: [64,102] vs. [64,204]\n\t [[{{node metrics/acc/Equal}}]]\n0 successful operations.\n0 derived errors ignored."]}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"0deb58fb-ff0d-4312-87a0-9672ab73a0af","executionInfo":{"status":"ok","timestamp":1571402046736,"user_tz":300,"elapsed":1224,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"id":"mBXfoLxfqxSi","colab":{"base_uri":"https://localhost:8080/","height":442}},"source":["from keras import backend as K \n","K.clear_session() \n","batch_size = 64\n","epochs = 100\n","num_neurons = 512\n","\n","encoder_inputs = Input(batch_shape=(batch_size, max_encoder_seq_length, input_vocab_size))\n","decoder_inputs = Input(batch_shape=(batch_size, max_decoder_seq_length, output_vocab_size))\n","\n","encoder_gru = GRU(num_neurons, return_sequences=True, return_state=True, name='encoder_gru')\n","encoder_outputs, encoder_state = encoder_gru(encoder_inputs)\n","\n","decoder_gru = GRU(num_neurons, return_sequences=True, return_state=True, name='decoder_gru')\n","decoder_outputs,decoder_state = decoder_gru(decoder_inputs,initial_state= encoder_state) \n","\n","attn_layer = AttentionLayer(name='attention_layer') \n","attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n","\n","# Concat attention output and decoder LSTM output \n","decoder_concat_input = Concatenate(axis=1, name='concat_layer')([decoder_outputs, attn_out])\n","\n","#Dense layer\n","dense = Dense(output_vocab_size, activation='softmax', name='softmax_layer')\n","decoder_time = TimeDistributed(dense, name = 'time_distributed_layer') \n","decoder_pred = decoder_time(decoder_concat_input) \n","\n","# Define the model\n","model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_pred) \n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(64, 100, 44)]      0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(64, 102, 46)]      0                                            \n","__________________________________________________________________________________________________\n","encoder_gru (GRU)               [(64, 100, 512), (64 855552      input_1[0][0]                    \n","__________________________________________________________________________________________________\n","decoder_gru (GRU)               [(64, 102, 512), (64 858624      input_2[0][0]                    \n","                                                                 encoder_gru[0][1]                \n","__________________________________________________________________________________________________\n","attention_layer (AttentionLayer ((64, None, 512), (6 524800      encoder_gru[0][0]                \n","                                                                 decoder_gru[0][0]                \n","__________________________________________________________________________________________________\n","concat_layer (Concatenate)      (64, None, 512)      0           decoder_gru[0][0]                \n","                                                                 attention_layer[0][0]            \n","__________________________________________________________________________________________________\n","time_distributed_layer (TimeDis (None, None, 46)     23598       concat_layer[0][0]               \n","==================================================================================================\n","Total params: 2,262,574\n","Trainable params: 2,262,574\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nKwukuqvY6MW","colab_type":"code","outputId":"eba47d53-3fab-4aa5-8ddb-2d4f98aafe68","executionInfo":{"status":"ok","timestamp":1571381741592,"user_tz":-330,"elapsed":1312,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["encoder_input_data.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(64350, 100, 44)"]},"metadata":{"tags":[]},"execution_count":126}]},{"cell_type":"code","metadata":{"id":"Hg6-XRDOR8y4","colab_type":"code","colab":{}},"source":["# Assemble the model for sequence generation\n","encoder_model = Model(encoder_inputs, encoder_states)\n","thought_input = [Input(shape=(num_neurons,)), Input(shape=(num_neurons,))]\n","decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=thought_input)\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","decoder_model = Model(inputs=[decoder_inputs] + thought_input,\n","                     outputs=[decoder_outputs] + decoder_states)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IVFC0o7zR805","colab_type":"code","colab":{}},"source":["# Build a character-based translator \n","def decode_sequence(input_seq):\n","  thought = encoder_model.predict(input_seq)\n","  \n","  target_seq = np.zeros((1,1,output_vocab_size))\n","  target_seq[0, 0, target_token_index[start_token]] = 1.\n","  stop_condition = False\n","  generated_sequence = ''\n","  \n","  while not stop_condition:\n","    output_tokens, h, c = decoder_model.predict([target_seq] + thought)\n","    generated_token_idx = np.argmax(output_tokens[0, -1, :])\n","    generated_char = reverse_target_char_index[generated_token_idx]\n","    generated_sequence += generated_char\n","    if (generated_char == stop_token or len(generated_sequence) > max_decoder_seq_length):\n","      stop_condition = True\n","    target_seq = np.zeros((1, 1, output_vocab_size))\n","    target_seq[0, 0, generated_token_idx] = 1.\n","    thought = [h, c]\n","  return generated_sequence"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AISNouHMR83P","colab_type":"code","colab":{}},"source":["# Generating a response\n","def response(input_text):\n","  input_seq = np.zeros((1, max_encoder_seq_length, input_vocab_size), dtype='float32')\n","  for t, char in enumerate(input_text):\n","    input_seq[0, t, input_token_index[char]] = 1.\n","  decoded_sentence = decode_sequence(input_seq)\n","  print('Bot Reply (Decoded sentence):', decoded_sentence)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gueEuDuuR85T","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mkyaTYO7R87w","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MEM04xPnR8-c","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ax1B8u-fR8t_","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M0YpQpUrR8sG","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XPJJ6re4IfnY","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CgdoOce7Ifqj","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2zdnTnjcIftd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4xz4oDivIfwN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MttpSq_bIfze","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ESaDvRSmIf2P","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zk-vOkdjIf8S","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Bkv5Ut0If_d","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MaCeaWgpIgCY","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"siaxngVwIgFK","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f7G4WwGBIf5T","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}