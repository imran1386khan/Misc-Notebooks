{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sequence2Sequence(Encoder-Decoder).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"53xgu7v-XMEo","colab_type":"code","outputId":"a5a387a6-c0d1-4fa4-e807-154465b32876","executionInfo":{"status":"ok","timestamp":1571019486519,"user_tz":-330,"elapsed":31975,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rB2QmaGgIJG6","colab_type":"code","outputId":"3d825e85-2285-4ab4-dad9-10e632ed5ec6","executionInfo":{"status":"ok","timestamp":1571367756698,"user_tz":-330,"elapsed":8608,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["!git clone https://github.com/totalgood/nlpia.git"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Cloning into 'nlpia'...\n","remote: Enumerating objects: 196, done.\u001b[K\n","remote: Counting objects: 100% (196/196), done.\u001b[K\n","remote: Compressing objects: 100% (118/118), done.\u001b[K\n","remote: Total 5827 (delta 98), reused 138 (delta 57), pack-reused 5631\u001b[K\n","Receiving objects: 100% (5827/5827), 124.02 MiB | 26.22 MiB/s, done.\n","Resolving deltas: 100% (3674/3674), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3FXYYs2FIpJU","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mDJryqyGIfIi","colab_type":"code","colab":{}},"source":["df = pd.read_csv('/content/nlpia/src/nlpia/data/moviedialog.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZCWX8-97IfMZ","colab_type":"code","colab":{}},"source":["df.drop(columns='Unnamed: 0', axis=1,inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QPzSUj5PIfPv","colab_type":"code","outputId":"13d77ece-3a49-4ab8-9164-089781805450","executionInfo":{"status":"ok","timestamp":1571367759091,"user_tz":-330,"elapsed":1059,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["df.head(5)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>statement</th>\n","      <th>reply</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>you're asking me out. that's so cute. what's y...</td>\n","      <td>forget it.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>no, no, it's my fault we didn't have a proper ...</td>\n","      <td>cameron.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>gosh, if only we could find kat a boyfriend...</td>\n","      <td>let me see what i can do.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>c'esc ma tete. this is my head</td>\n","      <td>right. see? you're ready for the quiz.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>how is our little find the wench a date plan p...</td>\n","      <td>well, there's someone i think might be</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                           statement                                    reply\n","0  you're asking me out. that's so cute. what's y...                               forget it.\n","1  no, no, it's my fault we didn't have a proper ...                                 cameron.\n","2     gosh, if only we could find kat a boyfriend...                let me see what i can do.\n","3                     c'esc ma tete. this is my head   right. see? you're ready for the quiz.\n","4  how is our little find the wench a date plan p...  well, there's someone i think might be "]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"swuzt1VyRXO3","colab_type":"code","colab":{}},"source":["input_texts, target_texts = [], []\n","input_vocabulary = set()\n","output_vocabulary = set()\n","start_token = '\\t'\n","stop_token = '\\n'\n","max_training_samples = min(25000, len(df) -1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"011FU8f_IfWC","colab_type":"code","colab":{}},"source":["for input_text, target_text in zip(df.statement, df.reply):\n","  target_text = start_token + target_text + stop_token\n","  input_texts.append(input_text)\n","  target_texts.append(target_text)\n","  for char in input_text:\n","    input_vocabulary.add(char)\n","  for char in target_text:\n","    output_vocabulary.add(char) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fg4G4YEgIfk2","colab_type":"code","colab":{}},"source":["input_vocabulary = sorted(input_vocabulary)\n","output_vocabulary = sorted(output_vocabulary)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M_x839TXR8jm","colab_type":"code","colab":{}},"source":["input_vocab_size = len(input_vocabulary)\n","output_vocab_size = len(output_vocabulary)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n8rHGRSXR8lp","colab_type":"code","colab":{}},"source":["max_encoder_seq_length = max([len(txt) for txt in input_texts])\n","max_decoder_seq_length = max([len(txt) for txt in target_texts])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZSn59RrkR8oA","colab_type":"code","colab":{}},"source":["input_token_index = dict((c,i) for i,c in enumerate(input_vocabulary))\n","target_token_index = dict((c,i) for i,c in enumerate(output_vocabulary))\n","\n","reverse_input_char_index = dict((i, c) for c, i in input_token_index.items())\n","reverse_target_char_index = dict((i, c) for c, i in target_token_index.items())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NEfR85y_VqTz","colab_type":"code","colab":{}},"source":["import numpy as np\n","encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, input_vocab_size), dtype = 'float32')\n","decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, output_vocab_size), dtype = 'float32')\n","decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, output_vocab_size), dtype='float32')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hNXfHc5eR8p7","colab_type":"code","colab":{}},"source":["for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n","  for t,c in enumerate(input_text):\n","    encoder_input_data[i, t, input_token_index[c]] = 1.\n","  for t,c in enumerate(target_text):\n","    decoder_input_data[i, t, target_token_index[c]] = 1.\n","    if t > 0:\n","      decoder_target_data[i, t-1, target_token_index[c]] = 1."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sC4sbhTsR8wi","colab_type":"code","outputId":"931f4e63-ab6c-41d7-bd9f-ddc49c4eca7c","executionInfo":{"status":"ok","timestamp":1571367803660,"user_tz":-330,"elapsed":2860,"user":{"displayName":"Imran Khan","photoUrl":"","userId":"09861086107683811678"}},"colab":{"base_uri":"https://localhost:8080/","height":496}},"source":["from keras.models import Model\n","from keras.layers import Input, LSTM, Dense\n","\n","batch_size = 64\n","epochs = 100\n","num_neurons = 256\n","\n","encoder_inputs = Input(shape=(None, input_vocab_size))\n","encoder = LSTM(num_neurons, return_state=True)\n","encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n","encoder_states = [state_h, state_c]\n","\n","decoder_inputs = Input(shape=(None, output_vocab_size))\n","decoder_lstm = LSTM(num_neurons, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n","decoder_dense = Dense(output_vocab_size, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","model.summary()\n","model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n","model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size = batch_size, epochs = epochs, validation_split=0.1)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, None, 44)     0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, None, 46)     0                                            \n","__________________________________________________________________________________________________\n","lstm_1 (LSTM)                   [(None, 256), (None, 308224      input_1[0][0]                    \n","__________________________________________________________________________________________________\n","lstm_2 (LSTM)                   [(None, None, 256),  310272      input_2[0][0]                    \n","                                                                 lstm_1[0][1]                     \n","                                                                 lstm_1[0][2]                     \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, None, 46)     11822       lstm_2[0][0]                     \n","==================================================================================================\n","Total params: 630,318\n","Trainable params: 630,318\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kliv4X9rHl_h","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hg6-XRDOR8y4","colab_type":"code","colab":{}},"source":["# Assemble the model for sequence generation\n","encoder_model = Model(encoder_inputs, encoder_states)\n","thought_input = [Input(shape=(num_neurons,)), Input(shape=(num_neurons,))]\n","decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=thought_input)\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","decoder_model = Model(inputs=[decoder_inputs] + thought_input,\n","                     outputs=[decoder_outputs] + decoder_states)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IVFC0o7zR805","colab_type":"code","colab":{}},"source":["# Build a character-based translator \n","def decode_sequence(input_seq):\n","  thought = encoder_model.predict(input_seq)\n","  \n","  target_seq = np.zeros((1,1,output_vocab_size))\n","  target_seq[0, 0, target_token_index[start_token]] = 1.\n","  stop_condition = False\n","  generated_sequence = ''\n","  \n","  while not stop_condition:\n","    output_tokens, h, c = decoder_model.predict([target_seq] + thought)\n","    generated_token_idx = np.argmax(output_tokens[0, -1, :])\n","    generated_char = reverse_target_char_index[generated_token_idx]\n","    generated_sequence += generated_char\n","    if (generated_char == stop_token or len(generated_sequence) > max_decoder_seq_length):\n","      stop_condition = True\n","    target_seq = np.zeros((1, 1, output_vocab_size))\n","    target_seq[0, 0, generated_token_idx] = 1.\n","    thought = [h, c]\n","  return generated_sequence"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AISNouHMR83P","colab_type":"code","colab":{}},"source":["# Generating a response\n","def response(input_text):\n","  input_seq = np.zeros((1, max_encoder_seq_length, input_vocab_size), dtype='float32')\n","  for t, char in enumerate(input_text):\n","    input_seq[0, t, input_token_index[char]] = 1.\n","  decoded_sentence = decode_sequence(input_seq)\n","  print('Bot Reply (Decoded sentence):', decoded_sentence)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gueEuDuuR85T","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mkyaTYO7R87w","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MEM04xPnR8-c","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ax1B8u-fR8t_","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M0YpQpUrR8sG","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XPJJ6re4IfnY","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CgdoOce7Ifqj","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2zdnTnjcIftd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4xz4oDivIfwN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MttpSq_bIfze","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ESaDvRSmIf2P","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zk-vOkdjIf8S","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Bkv5Ut0If_d","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MaCeaWgpIgCY","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"siaxngVwIgFK","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f7G4WwGBIf5T","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}